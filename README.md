# ğŸ¬ Diabetes Prediction with Machine Learning

This project predicts whether a person has diabetes based on diagnostic measurements. It uses the **Pima Indians Diabetes Dataset** and is implemented in a Jupyter Notebook using common data science libraries.

## ğŸ“Š Dataset

Source: [Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)  
The CSV file is included in the `data` folder.  
Shape: 768 rows Ã— 9 columns

## âš™ï¸ Technologies Used

- Python  
- Jupyter Notebook  
- Pandas, NumPy  
- Scikit-learn  
- Matplotlib, Seaborn  

## ğŸ—‚ï¸ Project Structure

- `notebooks/` â€” Jupyter notebook with the full analysis and model training  
- `data/` â€” Dataset files (CSV)  
- `requirements.txt` â€” List of required Python packages  
- `.gitignore` â€” Files and folders to ignore in git  

## ğŸš€ How to Run

1. Clone the repository:  
   ```bash
   git clone https://github.com/alirazmjooei/diabetes-prediction.git
   cd diabetes-prediction
   ```
2. Install dependencies:  
   ```bash
   pip install -r requirements.txt
   ```
3. Open the Jupyter notebook:  
   ```bash
   jupyter notebook notebooks/diabetes_prediction.ipynb
   ```

## ğŸ“ˆ Model Evaluation

I evaluated the Random Forest classifier on the diabetes dataset using several important metrics and visualizations:

- **Accuracy:** 72% overall accuracy on the test set.  
- **Classification Report:** Includes precision, recall, and F1-score for both classes (diabetic and non-diabetic).

### ğŸ” Key Visualizations

1. **ğŸ§® Confusion Matrix:**  
   Shows the counts of true positive, true negative, false positive, and false negative predictions, helping to understand the types of errors the model makes.

2. **â­ Feature Importance:**  
   Displays which features (e.g., glucose level, BMI) have the most impact on the modelâ€™s predictions, aiding interpretability.

3. **ğŸ“‰ ROC Curve:**  
   Illustrates the trade-off between true positive rate and false positive rate across different classification thresholds, with the Area Under Curve (AUC) indicating overall model performance.

These visualizations provide insights into the modelâ€™s strengths and weaknesses, ensuring a comprehensive evaluation beyond simple accuracy.
